# Brain_Tumor_segmentation

Brain tumors are abnormal growths of cells within the brain that can lead to severe neurological complications and even death. Accurate and early diagnosis of brain tumors is crucial for effective treatment and patient outcomes. Magnetic resonance imaging (MRI) is a commonly used diagnostic tool for brain tumors. However, the analysis of MRI scans to identify brain tumors is time-consuming and requires expert knowledge. The development of automated methods for brain tumor classification using machine learning techniques can assist clinicians in accurate and efficient diagnosis.

In recent years, Convolutional Neural Networks (CNNs) have shown remarkable success in image classification tasks, including brain tumor classification. MATLAB is a powerful tool for implementing CNNs due to its robust image processing and machine learning capabilities. In this study, we propose a brain tumor classification method using CNN implemented in MATLAB. The proposed method uses preprocessed MRI scans from the kaggle dataset and aims to classify brain tumors into two categories:tumor, and no tumor. The performance of the proposed method is evaluated using accuracy, precision, recall, and F1-score metrics. The results demonstrate the potential of the proposed method as a diagnostic tool to aid clinicians in identifying brain tumors accurately and quickly using MATLAB.
![image](https://user-images.githubusercontent.com/101940109/233795386-eb88f317-cf79-4243-868a-d7930fe713c7.png)
![image](https://user-images.githubusercontent.com/101940109/233795443-5c7262eb-5792-4b14-a2bc-09542c125291.png)


# Dataset:

The image data has been collected from kaggle(https://www.kaggle.com/datasets/navoneel/brain-mri-images-for-brain-tumor-detection). The dataset contains 255 jpg image files of tumors and no tumors. We have splitted the dataset in 8:1 ratio for training and testing respectively.
![image](https://user-images.githubusercontent.com/101940109/233795466-c1a741a6-811a-4a9e-95e3-10c58ac38bf0.png)

# Methodology:

As a first step in streamlining and deconstructing the raw data, we pre-process the images by making all of the images in the collection into 3-dimensional representations of standard sizes of (26,26,1). An integer between 0 and 255 corresponds to each pixel in the image. Four layers of convolution, batch normalization, reLU, and max pooling are applied to the images as part of the model training process. Before passing through a layer that is totally connected, this procedure is repeated four times, each time adding additional neurons.

# Convolution Neural Network (CNN):
CNN is a popular deep learning approach for image recognition and classification. It is part of a class of deep neural networks that only requires little pre-processing. The network is able to identify ambiguous patterns (edges) in the image more successfully when an image is input in small chunks rather than one pixel at a time. Convolutional, pooling (max and average), fully connected (FC), and normalizing layers are a few of the hidden layers that make up CNN's three levels, along with input, output, and other layers. CNN uses a filter (kernel), which is an array of weights, to extract features from the input picture. In order to introduce some non-linearity, each CNN layer utilizes a distinct activation function . While there are more channels when we enter CNN, the height and width are getting smaller. Using the generated column matrix, the outcome is eventually predicted.
![image](https://user-images.githubusercontent.com/101940109/233795547-64a984fa-35db-47ea-9518-58dbc3ef7c7a.png)

# Implementation:
For the image data, we therefore generated a convolution layer with a kernel of size 3 x 3 and initially 8 neurons along with a stride 1 and a padding to ensure the spatial output size is equal to the input size, in accordance with the specified architecture. Then, a batch normalisation layer is applied to the images, normalising the activations and gradients propagating through the network to make network training an easier optimisation task. The batch normalising layer is followed by a nonlinear activation function called reLU. After convolutional layers (with activation functions), a down-sampling approach may be used to reduce the spatial size of the feature map and remove superfluous spatial data. Downsampling allows for deeper convolutional layers to accommodate more filters without increasing the amount of processing required for each layer. One technique for downsampling is to use maximum pooling. The highest values of rectangular input regions are specified by the first argument, pool size, and are returned by the max pooling layer. This paper's rectangular area measures [2,2]. The 'Stride' name-value pair input controls the step size used by the training function when scanning the data.
Three further iterations of this procedure are performed, increasing the number of neurons from 8 to 16 to 32 and eventually 64 each time. Ultimately, a Fully Connected Layer receives the photos. As the name suggests, a completely linked layer is one in which all of its neurons connect to every neuron in the layer above it. This layer integrates all the information that the other layers have learned to find the bigger patterns in the image. The final fully connected layer combines the attributes to categorise the photos. As a result, the Output Size parameter in the final fully connected layer's output size corresponds to the number of classes in the target data. The output size is 2, which corresponds to the 2 classes. Next, the output of the fully linked layer is normalised by the softmax activation function. The output of the softmax layer is a set of positive values that total one, which the classification layer (the last layer) can use to calculate classification probabilities. Using the probabilities provided by the softmax activation function for each input, this layer computes the loss and categorises each input into one of the classes that are mutually exclusive.

# Result:

Using stochastic gradient descent with momentum (SGDM), the network was trained with a maximum number of epochs of 10 and an initial learning rate of 0.01. By defining the validation data and validation frequency, we kept track of the network's accuracy as it was being trained. At each epoch, the data was changed. The software calculated the accuracy on the validation data at regular intervals while training the network using the training data. Using the CNN model, we were able to finally attain an accuracy of 96.04% for this dataset.
![image](https://user-images.githubusercontent.com/101940109/233795634-c45a425f-93d9-4427-a28f-2252c1e27aef.png)
The total number of iterations was 30, with 3 iterations for each epoch. The model's loss curve looks like this.
![image](https://user-images.githubusercontent.com/101940109/233795659-ae288c5b-4eec-4bb7-829f-9f7bb50fff2f.png)
![image](https://user-images.githubusercontent.com/101940109/233795670-f0c2e0c6-dfec-4877-b4e9-c77a1c4f438c.png)
From the confusion matrix, we can see that the accuracy is 96.0% with the error percentage being 4.0%.

